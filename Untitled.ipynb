{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "112f7561-7f67-4b6e-b22d-a90ca43f213e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langgraph in ./venv/lib/python3.10/site-packages (0.5.3)\n",
      "Requirement already satisfied: langchain_community in ./venv/lib/python3.10/site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain_anthropic in ./venv/lib/python3.10/site-packages (0.3.17)\n",
      "Requirement already satisfied: langchain-tavily in ./venv/lib/python3.10/site-packages (0.2.10)\n",
      "Requirement already satisfied: langchain_experimental in ./venv/lib/python3.10/site-packages (0.3.4)\n",
      "Requirement already satisfied: langchain-core>=0.1 in ./venv/lib/python3.10/site-packages (from langgraph) (0.3.69)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in ./venv/lib/python3.10/site-packages (from langgraph) (2.1.0)\n",
      "Requirement already satisfied: langgraph-prebuilt<0.6.0,>=0.5.0 in ./venv/lib/python3.10/site-packages (from langgraph) (0.5.1)\n",
      "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in ./venv/lib/python3.10/site-packages (from langgraph) (0.1.72)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in ./venv/lib/python3.10/site-packages (from langgraph) (2.11.7)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in ./venv/lib/python3.10/site-packages (from langgraph) (3.5.0)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in ./venv/lib/python3.10/site-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph) (1.10.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in ./venv/lib/python3.10/site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in ./venv/lib/python3.10/site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.18)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in ./venv/lib/python3.10/site-packages (from langchain_community) (0.3.26)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./venv/lib/python3.10/site-packages (from langchain_community) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in ./venv/lib/python3.10/site-packages (from langchain_community) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./venv/lib/python3.10/site-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./venv/lib/python3.10/site-packages (from langchain_community) (3.12.13)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in ./venv/lib/python3.10/site-packages (from langchain_community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in ./venv/lib/python3.10/site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in ./venv/lib/python3.10/site-packages (from langchain_community) (2.10.1)\n",
      "Requirement already satisfied: langsmith>=0.1.125 in ./venv/lib/python3.10/site-packages (from langchain_community) (0.4.4)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in ./venv/lib/python3.10/site-packages (from langchain_community) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.26.2 in ./venv/lib/python3.10/site-packages (from langchain_community) (2.2.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in ./venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./venv/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./venv/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in ./venv/lib/python3.10/site-packages (from langchain<1.0.0,>=0.3.26->langchain_community) (0.3.8)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./venv/lib/python3.10/site-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./venv/lib/python3.10/site-packages (from langchain-core>=0.1->langgraph) (4.14.0)\n",
      "Requirement already satisfied: packaging>=23.2 in ./venv/lib/python3.10/site-packages (from langchain-core>=0.1->langgraph) (24.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.10/site-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./venv/lib/python3.10/site-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./venv/lib/python3.10/site-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in ./venv/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (2025.6.15)\n",
      "Requirement already satisfied: greenlet>=1 in ./venv/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./venv/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.1.0)\n",
      "Requirement already satisfied: anthropic<1,>=0.57.0 in ./venv/lib/python3.10/site-packages (from langchain_anthropic) (0.57.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./venv/lib/python3.10/site-packages (from anthropic<1,>=0.57.0->langchain_anthropic) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./venv/lib/python3.10/site-packages (from anthropic<1,>=0.57.0->langchain_anthropic) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./venv/lib/python3.10/site-packages (from anthropic<1,>=0.57.0->langchain_anthropic) (0.10.0)\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.10/site-packages (from anthropic<1,>=0.57.0->langchain_anthropic) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->anthropic<1,>=0.57.0->langchain_anthropic) (1.3.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.10/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./venv/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.16.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./venv/lib/python3.10/site-packages (from langsmith>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in ./venv/lib/python3.10/site-packages (from langsmith>=0.1.125->langchain_community) (0.23.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U langgraph langchain_community langchain_anthropic langchain-tavily langchain_experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f96d261a-ec17-40af-bd92-c56346a05d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "\n",
    "def _set_if_undefined(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"Please provide your {var}\")\n",
    "\n",
    "\n",
    "_set_if_undefined(\"OPENAI_API_KEY\")\n",
    "_set_if_undefined(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edb7626b-666a-41c4-898c-1e433a66b371",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, List\n",
    "\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_tavily import TavilySearch\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "tavily_tool = TavilySearch(max_results=5)\n",
    "\n",
    "\n",
    "@tool\n",
    "def scrape_webpages(urls: List[str]) -> str:\n",
    "    \"\"\"Use requests and bs4 to scrape the provided web pages for detailed information.\"\"\"\n",
    "    loader = WebBaseLoader(urls)\n",
    "    docs = loader.load()\n",
    "    return \"\\n\\n\".join(\n",
    "        [\n",
    "            f'<Document name=\"{doc.metadata.get(\"title\", \"\")}\">\\n{doc.page_content}\\n</Document>'\n",
    "            for doc in docs\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25cf0ab9-983c-4064-b9e2-0d11f5a50942",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tempfile import TemporaryDirectory\n",
    "from typing import Dict, Optional\n",
    "\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "_TEMP_DIRECTORY = TemporaryDirectory()\n",
    "WORKING_DIRECTORY = Path(_TEMP_DIRECTORY.name)\n",
    "\n",
    "\n",
    "@tool\n",
    "def create_outline(\n",
    "    points: Annotated[List[str], \"List of main points or sections.\"],\n",
    "    file_name: Annotated[str, \"File path to save the outline.\"],\n",
    ") -> Annotated[str, \"Path of the saved outline file.\"]:\n",
    "    \"\"\"Create and save an outline.\"\"\"\n",
    "    with (WORKING_DIRECTORY / file_name).open(\"w\") as file:\n",
    "        for i, point in enumerate(points):\n",
    "            file.write(f\"{i + 1}. {point}\\n\")\n",
    "    return f\"Outline saved to {file_name}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def read_document(\n",
    "    file_name: Annotated[str, \"File path to read the document from.\"],\n",
    "    start: Annotated[Optional[int], \"The start line. Default is 0\"] = None,\n",
    "    end: Annotated[Optional[int], \"The end line. Default is None\"] = None,\n",
    ") -> str:\n",
    "    \"\"\"Read the specified document.\"\"\"\n",
    "    with (WORKING_DIRECTORY / file_name).open(\"r\") as file:\n",
    "        lines = file.readlines()\n",
    "    if start is None:\n",
    "        start = 0\n",
    "    return \"\\n\".join(lines[start:end])\n",
    "\n",
    "\n",
    "@tool\n",
    "def write_document(\n",
    "    content: Annotated[str, \"Text content to be written into the document.\"],\n",
    "    file_name: Annotated[str, \"File path to save the document.\"],\n",
    ") -> Annotated[str, \"Path of the saved document file.\"]:\n",
    "    \"\"\"Create and save a text document.\"\"\"\n",
    "    with (WORKING_DIRECTORY / file_name).open(\"w\") as file:\n",
    "        file.write(content)\n",
    "    return f\"Document saved to {file_name}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def edit_document(\n",
    "    file_name: Annotated[str, \"Path of the document to be edited.\"],\n",
    "    inserts: Annotated[\n",
    "        Dict[int, str],\n",
    "        \"Dictionary where key is the line number (1-indexed) and value is the text to be inserted at that line.\",\n",
    "    ],\n",
    ") -> Annotated[str, \"Path of the edited document file.\"]:\n",
    "    \"\"\"Edit a document by inserting text at specific line numbers.\"\"\"\n",
    "\n",
    "    with (WORKING_DIRECTORY / file_name).open(\"r\") as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    sorted_inserts = sorted(inserts.items())\n",
    "\n",
    "    for line_number, text in sorted_inserts:\n",
    "        if 1 <= line_number <= len(lines) + 1:\n",
    "            lines.insert(line_number - 1, text + \"\\n\")\n",
    "        else:\n",
    "            return f\"Error: Line number {line_number} is out of range.\"\n",
    "\n",
    "    with (WORKING_DIRECTORY / file_name).open(\"w\") as file:\n",
    "        file.writelines(lines)\n",
    "\n",
    "    return f\"Document edited and saved to {file_name}\"\n",
    "\n",
    "\n",
    "# Warning: This executes code locally, which can be unsafe when not sandboxed\n",
    "\n",
    "repl = PythonREPL()\n",
    "\n",
    "\n",
    "@tool\n",
    "def python_repl_tool(\n",
    "    code: Annotated[str, \"The python code to execute to generate your chart.\"],\n",
    "):\n",
    "    \"\"\"Use this to execute python code. If you want to see the output of a value,\n",
    "    you should print it out with `print(...)`. This is visible to the user.\"\"\"\n",
    "    try:\n",
    "        result = repl.run(code)\n",
    "    except BaseException as e:\n",
    "        return f\"Failed to execute. Error: {repr(e)}\"\n",
    "    return f\"Successfully executed:\\n\\`\\`\\`python\\n{code}\\n\\`\\`\\`\\nStdout: {result}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d084a0a5-ca5d-4b2b-988b-68375ddabac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional, Literal, TypedDict\n",
    "from langchain_core.language_models.chat_models import BaseChatModel\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langgraph.types import Command\n",
    "from langchain_core.messages import HumanMessage, trim_messages\n",
    "\n",
    "\n",
    "class State(MessagesState):\n",
    "    next: str\n",
    "\n",
    "\n",
    "def make_supervisor_node(llm: BaseChatModel, members: list[str]):\n",
    "    options = [\"FINISH\"] + members\n",
    "    system_prompt = (\n",
    "        \"You are a supervisor tasked with managing a conversation between the\"\n",
    "        f\" following workers: {members}. Given the following user request,\"\n",
    "        \" respond with the worker to act next. Each worker will perform a\"\n",
    "        \" task and respond with their results and status. When finished,\"\n",
    "        \" respond with FINISH.\"\n",
    "    )\n",
    "\n",
    "    # Manually expand the options for Python 3.10\n",
    "    class Router(TypedDict):\n",
    "        next: Literal[\"FINISH\", \"supervisor\",\"web_scraper\"]  # update manually\n",
    "\n",
    "    def supervisor_node(state: State) -> Command[Literal[\"worker1\", \"worker2\", \"__end__\"]]:\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "        ] + state[\"messages\"]\n",
    "        response = llm.with_structured_output(Router).invoke(messages)\n",
    "        goto = response[\"next\"]\n",
    "        if goto == \"FINISH\":\n",
    "            goto = END\n",
    "\n",
    "        return Command(goto=goto, update={\"next\": goto})\n",
    "\n",
    "    return supervisor_node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f6021fe-05fe-40e0-8788-fd2515d6fb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "search_agent = create_react_agent(llm, tools=[tavily_tool])\n",
    "\n",
    "\n",
    "def search_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    result = search_agent.invoke(state)\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"search\")\n",
    "            ]\n",
    "        },\n",
    "        # We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
    "        goto=\"supervisor\",\n",
    "    )\n",
    "\n",
    "\n",
    "web_scraper_agent = create_react_agent(llm, tools=[scrape_webpages])\n",
    "\n",
    "\n",
    "def web_scraper_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    result = web_scraper_agent.invoke(state)\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"web_scraper\")\n",
    "            ]\n",
    "        },\n",
    "        # We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
    "        goto=\"supervisor\",\n",
    "    )\n",
    "\n",
    "\n",
    "research_supervisor_node = make_supervisor_node(llm, [\"search\", \"web_scraper\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73a1b605-6200-41c3-9c22-e0900e4964c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found edge ending at unknown node `worker1`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m research_builder\u001b[38;5;241m.\u001b[39madd_node(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweb_scraper\u001b[39m\u001b[38;5;124m\"\u001b[39m, web_scraper_node)\n\u001b[1;32m      6\u001b[0m research_builder\u001b[38;5;241m.\u001b[39madd_edge(START, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupervisor\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m research_graph \u001b[38;5;241m=\u001b[39m \u001b[43mresearch_builder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Project/Demo-agent/venv/lib/python3.10/site-packages/langgraph/graph/state.py:822\u001b[0m, in \u001b[0;36mStateGraph.compile\u001b[0;34m(self, checkpointer, cache, store, interrupt_before, interrupt_after, debug, name)\u001b[0m\n\u001b[1;32m    819\u001b[0m interrupt_after \u001b[38;5;241m=\u001b[39m interrupt_after \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[1;32m    821\u001b[0m \u001b[38;5;66;03m# validate the graph\u001b[39;00m\n\u001b[0;32m--> 822\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m*\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minterrupt_after\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m*\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;66;03m# prepare output channels\u001b[39;00m\n\u001b[1;32m    831\u001b[0m output_channels \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    832\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__root__\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    833\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschemas[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_schema]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    839\u001b[0m     ]\n\u001b[1;32m    840\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/Project/Demo-agent/venv/lib/python3.10/site-packages/langgraph/graph/state.py:777\u001b[0m, in \u001b[0;36mStateGraph.validate\u001b[0;34m(self, interrupt)\u001b[0m\n\u001b[1;32m    775\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m target \u001b[38;5;129;01min\u001b[39;00m all_targets:\n\u001b[1;32m    776\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m target \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes \u001b[38;5;129;01mand\u001b[39;00m target \u001b[38;5;241m!=\u001b[39m END:\n\u001b[0;32m--> 777\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound edge ending at unknown node `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    778\u001b[0m \u001b[38;5;66;03m# validate interrupts\u001b[39;00m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interrupt:\n",
      "\u001b[0;31mValueError\u001b[0m: Found edge ending at unknown node `worker1`"
     ]
    }
   ],
   "source": [
    "research_builder = StateGraph(State)\n",
    "research_builder.add_node(\"supervisor\", research_supervisor_node)\n",
    "research_builder.add_node(\"search\", search_node)\n",
    "research_builder.add_node(\"web_scraper\", web_scraper_node)\n",
    "\n",
    "research_builder.add_edge(START, \"supervisor\")\n",
    "research_graph = research_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e96976-b5f9-4905-bf7f-f8e7cdc4cf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(research_graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1718ab9b-8ba4-4011-add6-a9f382501608",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
